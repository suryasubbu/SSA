{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "from yt_dlp import YoutubeDL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import whisper \n",
    "from stable_whisper import modify_model\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import librosa\n",
    "import config as config\n",
    "from pydub import AudioSegment\n",
    "\n",
    "out_dir = \"dummy/\"\n",
    "threshold = 10\n",
    "speaker_name = \"dumm\"\n",
    "\n",
    "def parse_time(timestamp):\n",
    "    \"\"\"\n",
    "    Converts a timestamp in HH:MM:SS format to seconds.\n",
    "    \n",
    "    Parameters:\n",
    "    - timestamp: str, time in HH:MM:SS format.\n",
    "    \n",
    "    Returns:\n",
    "    - total_seconds: float, total time in seconds.\n",
    "    \"\"\"\n",
    "    h, m, s = map(float, timestamp.split(':'))\n",
    "    total_seconds = h * 3600 + m * 60 + s\n",
    "    return total_seconds\n",
    "\n",
    "def trim_and_overwrite_audio(input_file, start_time_str):\n",
    "    \"\"\"\n",
    "    Trims the audio file from a given start time to the end and overwrites the original file.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_file: str, path to the input WAV file.\n",
    "    - start_time_str: str, start time in HH:MM:SS format where the trim should begin.\n",
    "    \"\"\"\n",
    "    # Parse the start time\n",
    "    start_time = parse_time(start_time_str)\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_file)\n",
    "    \n",
    "    # Calculate the start time in milliseconds\n",
    "    start_time_ms = start_time * 1000\n",
    "    \n",
    "    # Trim the audio from start_time to the end\n",
    "    trimmed_audio = audio[start_time_ms:]\n",
    "    \n",
    "    # Overwrite the original file with the trimmed audio\n",
    "    trimmed_audio.export(input_file, format=\"wav\")\n",
    "    print(f\"Audio trimmed and original file overwritten\")\n",
    "def clupping(a):\n",
    "    grouped_segments = []\n",
    "    current_group = []\n",
    "    current_duration = 0.0\n",
    "    a['start_diff'] = a['start'].diff().shift(-1)\n",
    "    a['start_diff'] = a['start_diff'].fillna(a[\"total\"])\n",
    "    print(a)\n",
    "    # Iterate over the dataframe rows\n",
    "    for idx, row in a.iterrows():\n",
    "        try:\n",
    "            if current_duration < threshold :\n",
    "\n",
    "                if current_duration + row['start_diff'] > threshold:\n",
    "                    # Combine the text of the current group\n",
    "                    combined_text = ' '.join([segment['text'] for segment in current_group])\n",
    "                    print(combined_text)\n",
    "                    # Create a new row for the grouped segments\n",
    "                    new_row = {\n",
    "                        'segment_no': [segment['segment_no'] for segment in current_group],\n",
    "                        'start': current_group[0]['start'],\n",
    "                        'end': current_group[-1]['end'],\n",
    "                        'text': combined_text,\n",
    "                        'total': current_duration,\n",
    "                        'word_count': sum(segment['word_count'] for segment in current_group)\n",
    "                    }\n",
    "                    \n",
    "                    # Add the new row to the list of grouped segments\n",
    "                    grouped_segments.append(new_row)\n",
    "                    \n",
    "                    # Reset the current group and duration\n",
    "                    current_group = []\n",
    "                    current_duration = 0.0\n",
    "            \n",
    "            else:\n",
    "                    \n",
    "                    # Create a new row for the grouped segments\n",
    "                    new_row = {\n",
    "                        'segment_no': row[\"segment_no\"],\n",
    "                        'start': row['start'],\n",
    "                        'end': row['end'],\n",
    "                        'text': row[\"text\"],\n",
    "                        'total': row[\"total\"],\n",
    "                        'word_count':  row[\"word_count\"]\n",
    "                    }\n",
    "                    \n",
    "                    # Add the new row to the list of grouped segments\n",
    "                    grouped_segments.append(new_row)\n",
    "                    \n",
    "                    # Reset the current group and duration\n",
    "                    current_group = []\n",
    "                    current_duration = 0.0\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # Add the current row to the group\n",
    "        current_group.append(row)\n",
    "        current_duration += row['start_diff']\n",
    "\n",
    "    # If there are any remaining rows in the current group, add them as a final segment\n",
    "    if current_group:\n",
    "        combined_text = ' '.join([segment['text'] for segment in current_group])\n",
    "        new_row = {\n",
    "            'segment_no': [segment['segment_no'] for segment in current_group],\n",
    "            'start': current_group[0]['start'],\n",
    "            'end': current_group[-1]['end'],\n",
    "            'text': combined_text,\n",
    "            'total': current_duration,\n",
    "            'word_count': sum(segment['word_count'] for segment in current_group)\n",
    "        }\n",
    "        grouped_segments.append(new_row)\n",
    "\n",
    "    # Convert the list of grouped segments to a new dataframe\n",
    "    grouped_df = pd.DataFrame(grouped_segments)\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "\n",
    "def word_count(row):\n",
    "    return len(row.split())\n",
    "\n",
    "def isMusic(path):\n",
    "        y, sr = librosa.load(path, sr = None)\n",
    "        splits = librosa.effects.split(y = y, frame_length = 500, top_db = 5)\n",
    "\n",
    "        if splits.size <= 5:\n",
    "                return True\n",
    "        else:\n",
    "                return False\n",
    "        \n",
    "def rem_music(d_path):\n",
    "     cc = []\n",
    "     data_dir = d_path\n",
    "     file_paths = pd.DataFrame({\n",
    "     \"path\": [os.path.join(data_dir, filename) for filename in os.listdir(data_dir) if filename.lower().endswith('.wav') and os.path.isfile(os.path.join(data_dir, filename))]\n",
    "     })\n",
    "     for index, row in file_paths.iterrows():\n",
    "        try:\n",
    "            if isMusic(row[\"path\"]):\n",
    "                print(f\"Is Music: {isMusic(row[\"path\"])}\",row[\"path\"])\n",
    "                cc.append = row[\"path\"]\n",
    "                os.remove(row[\"path\"])\n",
    "                print(\"removed\",row[\"path\"])\n",
    "        except:\n",
    "             continue\n",
    "     print(cc)\n",
    "def sentence_splitter(input_file,i,aout_dir = f\"{out_dir}/{speaker_name}/\"):\n",
    "    output_directory = aout_dir\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    model = whisper.load_model('medium.en')\n",
    "    model2 = whisper.load_model('large-v2')\n",
    "    # result1 = model.transcribe('/home/suryasss/Barack Obama_ Yes We Can.mp3', language='en', max_initial_timestamp=None)\n",
    "    modify_model(model)\n",
    "    result2 = model.transcribe(input_file, language='en') \n",
    "    a = result2.segments\n",
    "    # print(a)\n",
    "    data = {\n",
    "    'segment_no': range(0, len(a)),\n",
    "    'start': [segment.start for segment in a],\n",
    "    'end': [segment.end for segment in a],\n",
    "    'text': [segment.text for segment in a]\n",
    "    }\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    # Load the original audio file\n",
    "    original_audio = AudioSegment.from_file(input_file)\n",
    "\n",
    "    # Initialize the final audio segment\n",
    "    final_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Define the duration for non-segment to be added (1 second)\n",
    "    non_segment_duration = 0.2 * 1000  # pydub works with milliseconds\n",
    "\n",
    "    # Initialize a list to store updated segment times\n",
    "    updated_times = []\n",
    "\n",
    "    # Track the current position in the final_audio\n",
    "    current_position = 0\n",
    "    df[\"shifted_start\"] = df[\"start\"].shift(-1).fillna(df[\"end\"])\n",
    "    df[\"end\"] = np.where((df[\"end\"] + 0.3) >= df[\"shifted_start\"],df[\"shifted_start\"],df[\"end\"] + 0.3)\n",
    "    # Append the first segment\n",
    "    first_segment_start_time = df.iloc[0]['start'] * 1000  # Convert to milliseconds\n",
    "    first_segment_end_time = df.iloc[0]['end'] * 1000  # Convert to milliseconds\n",
    "    first_segment = original_audio[first_segment_start_time:first_segment_end_time]\n",
    "    final_audio += first_segment\n",
    "\n",
    "    updated_times.append({\n",
    "        'segment_no': df.iloc[0]['segment_no'],\n",
    "        'start': current_position / 1000,  # Convert back to seconds\n",
    "        'end': (current_position + len(first_segment)) / 1000  # Convert back to seconds\n",
    "    })\n",
    "\n",
    "    # Update current position\n",
    "    current_position += len(first_segment)\n",
    "\n",
    "    # Loop through each pair of segments\n",
    "    for t in range(1, len(df)):\n",
    "        prev_segment_end_time = df.iloc[t-1]['end'] * 1000  # End of previous segment\n",
    "        current_segment_start_time = df.iloc[t]['start'] * 1000  # Start of current segment\n",
    "        current_segment_end_time = df.iloc[t]['end'] * 1000  # End of current segment\n",
    "        \n",
    "        # Calculate the duration of gap to use\n",
    "        gap_duration = min(non_segment_duration, current_segment_start_time - prev_segment_end_time)\n",
    "        \n",
    "        # Add the non-segment part\n",
    "        if gap_duration > 0.5:\n",
    "            non_segment = original_audio[prev_segment_end_time:prev_segment_end_time + gap_duration]\n",
    "        else:\n",
    "            non_segment = AudioSegment.silent(duration=0.5)\n",
    "        final_audio += non_segment\n",
    "        current_position += len(non_segment)\n",
    "        \n",
    "        # Add the current segment\n",
    "        current_segment = original_audio[current_segment_start_time:current_segment_end_time]\n",
    "        final_audio += current_segment\n",
    "        \n",
    "        # Store the updated times\n",
    "        updated_times.append({\n",
    "            'segment_no': df.iloc[t]['segment_no'],\n",
    "            'start': current_position / 1000,  # Convert back to seconds\n",
    "            'end': (current_position + len(current_segment)) / 1000  # Convert back to seconds\n",
    "        })\n",
    "        \n",
    "        # Update current position\n",
    "        current_position += len(current_segment)\n",
    "\n",
    "    # Create a new DataFrame with updated times\n",
    "    updated_df = pd.DataFrame(updated_times)\n",
    "    updated_df[\"text\"] = df[\"text\"]\n",
    "    updated_df[\"total\"] = updated_df.end - updated_df.start\n",
    "    updated_df['word_count'] = updated_df['text'].apply(word_count) \n",
    "    adf = clupping(updated_df)\n",
    "    fil_df = adf[adf.total > (threshold/1.75)][adf.word_count >= 6].reset_index(drop = True)\n",
    "    j = i+len(fil_df[\"end\"])\n",
    "    b = np.arange(i,j)\n",
    "    fil_df[\"inde\"] = b\n",
    "    fil_df['filename'] = fil_df['inde'].apply(lambda x: f'{speaker_name}_{x:05d}.wav')\n",
    "    print(fil_df.shape)\n",
    "    is_music = []\n",
    "    texted = []\n",
    "    for index, row in fil_df.iterrows():\n",
    "        end_time = row['end']\n",
    "        start_time = row['start']\n",
    "        duration = end_time - start_time  # Calculate duration of the chunk\n",
    "        output_file = os.path.join(aout_dir, f\"{speaker_name}_{i:05d}.wav\")  # Output file path for each chunk\n",
    "        \n",
    "        chunk =  final_audio[start_time * 1000:(end_time * 1000)]\n",
    "        \n",
    "        # print(isMusic(chunk))\n",
    "        chunk.export(output_file, format=\"wav\")\n",
    "        text = model2.transcribe(output_file,language='en')\n",
    "        texted.append(text[\"text\"])\n",
    "        is_music.append(isMusic(output_file))\n",
    "        i = i+1 \n",
    "    fil_df[\"ismusic\"]   = is_music \n",
    "    fil_df[\"texted\"]    = texted\n",
    "    fil_df.drop_duplicates(\"texted\",inplace = True)\n",
    "    print(\"after dropping duplicates\",fil_df.shape)\n",
    "    fil_df[[\"filename\",\"text\",\"texted\",\"start\",\"end\",\"ismusic\"]].to_csv(f'{out_dir}/{speaker_name}/meta_chunk_{i-1}.csv',index = False)\n",
    "    return i,fil_df[[\"filename\",\"texted\",\"start\",\"end\"]]\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryasss/.conda/envs/ssconda/lib/python3.12/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "Transcribe: 100%|██████████| 1771.05/1771.05 [02:33<00:00, 11.57sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     segment_no    start      end  \\\n",
      "0             0     0.00     1.08   \n",
      "1             1     1.28     2.56   \n",
      "2             2     2.76     4.56   \n",
      "3             3     4.76     5.06   \n",
      "4             4     5.26     8.12   \n",
      "..          ...      ...      ...   \n",
      "431         431  1174.51  1175.19   \n",
      "432         432  1175.19  1176.39   \n",
      "433         433  1176.39  1177.83   \n",
      "434         434  1177.91  1179.01   \n",
      "435         435  1179.03  1180.95   \n",
      "\n",
      "                                                  text  total  word_count  \\\n",
      "0                                 I love you guys too.   1.08           5   \n",
      "1                                 I grew up in a place   1.28           6   \n",
      "2               a lot like this one called Middletown,   1.80           7   \n",
      "3                                                Ohio.   0.30           1   \n",
      "4     And that's where I learned the values of loya...   2.86           9   \n",
      "..                                                 ...    ...         ...   \n",
      "431                                        my friends.   0.68           2   \n",
      "432                              Let's do it together.   1.20           4   \n",
      "433                                I know that we can.   1.44           5   \n",
      "434                                     Thank you all.   1.10           3   \n",
      "435               God bless you and God bless America.   1.92           7   \n",
      "\n",
      "     start_diff  \n",
      "0          1.28  \n",
      "1          1.48  \n",
      "2          2.00  \n",
      "3          0.50  \n",
      "4          3.06  \n",
      "..          ...  \n",
      "431        0.68  \n",
      "432        1.20  \n",
      "433        1.52  \n",
      "434        1.12  \n",
      "435        1.92  \n",
      "\n",
      "[436 rows x 7 columns]\n",
      " I love you guys too.  I grew up in a place  a lot like this one called Middletown,  Ohio.  And that's where I learned the values of loyalty,  family,\n",
      " duty,  and honor.  And that's where I decided to do a list in the United States Marine Corps when I graduated  from high school in 2003.  Now it's also where I learned\n",
      " that if you grow up poor,  come from a chaotic family,  and get D's and F's in English,  you can still by the grace of God write a best-selling book\n",
      " and become the nominee to be your next Vice President of the United States of America.  Now my friends, I want to say I make a simple pledge.\n",
      " President Trump and I make a simple pledge that we will pour out every last drop of sweat,  we will work our tails off,\n",
      " and we will make America great again.  And we're going to do it together.  Now,  we've got to talk about the news of the day here, right?\n",
      " I was swimming with my kids yesterday,  and my wife told me that Joe Biden had decided to withdraw from the presidential race.  Now, see, you guys are excited about that.\n",
      " I don't know.  I was looking forward to debating Kamala Harris, actually.  So to the Democrats who are watching,\n",
      " please find some way to  make Kamala Vice President.  I was promised a debate with Kamala Harris,  and that's what I plan to get.\n",
      " Now history will remember Joe Biden as not just a quitter,\n",
      " which he is, but one of the worst presidents of the United States of America.  But my friends,  Kamala Harris is a million times worse,\n",
      " and everybody knows it.  She lied about every single one of Joe Biden's failures,  and she lied about his mental capacity to serve as president.\n",
      " Our country has been saddled for three and a half years with a president who cannot do the job.\n",
      " And that is all because Kamala Harris and the rest of the Democrats lied about his ability to be our president.\n",
      " We're going to kick them all out come November and replace them with some people who care about this country.  Ladies and gentlemen,\n",
      " she hasn't talked to the chief of Border Patrol a single time in her entire tenure as borders are.\n",
      " Remember, on her very first day in office,  she and Biden suspended deportations.\n",
      " They stopped construction of the border wall and they re-implemented catch and release.  The border crisis is a Kamala Harris crisis.\n",
      " Let's not her ever let her ever forget.  Let's never stop reminding her of that fact,  and let's never stop reminding people the fact that when President Trump was president,\n",
      " we had a secure border and we put our citizens first.  Now it doesn't stop there.\n",
      " Harris is actually even more extreme than Biden,  even though that's hard to believe.  She wants to totally decriminalize illegal immigration.  Well,  Kamala.  If you'd make it,\n",
      " if you stop making the crime to come into this country illegally,  you're just going to invite more and more illegal aliens.  And we know that communities like Radford and Middletown,\n",
      " we're the ones who suffer the consequences.  Now,  I know this area has been affected by a lot of stupid trade deals,\n",
      " a lot of deals that have shipped good American manufacturing jobs overseas.  Well, Biden supported NAFTA back in 1994,\n",
      " but Kamala Harris voted to keep NAFTA again and again,  even after it was obvious that it was a disaster for our people.  I agree.\n",
      " She voted to eliminate the filibuster and pass the Green New Scan,  destroying energy jobs in Virginia and Pennsylvania.  And driving up the cost of goods.\n",
      " That's why we've got an affordability crisis in this country, my friends,  because Joe Biden and Kamala Harris,\n",
      " they'd rather buy oil and gas from tin pot dictators all over the world.  I say they should buy it right here from American workers and from America.  It's simple.\n",
      " Drill, baby, drill.  It's not that complicated.  We've got it right here.  Our own workers want to get it out of the ground.  Why don't we just let them?  It'll  make our country stronger.\n",
      " We all know that's the case.  You know,  it gets even worse.  She  She supported abolishing ICE and wanted to defund the police.\n",
      " Even Joe Biden never went so far as to say he wanted to defund the police.\n",
      " Of course he supported all these policies because him or somebody else,  we don't know who's been in charge of this country the last three and a half years,  but Joe Biden supported\n",
      " it every step of the way or at least the person who's actually running the show,  she wants to ban fracking.  She said that.  You can go and look it up.\n",
      " She said that she wanted to ban fracking.  That is going to destroy hundreds of thousands of energy jobs all across our country.\n",
      " It's going to empower the very worst and the very most dangerous regimes in the world.  This is crazy.  There is simply no way\n",
      " that you can sit here and say the policies of Joe Biden have worked,  which is to say that we got to kick Kamala Harris out of the Oval Office.  Don't give her a chance.\n",
      " Don't give her a chance to run away from the Biden record.  The Biden record is the Kamala Harris record.  And given what we know about Joe Biden,\n",
      " Kamala Harris probably did a lot more than Joe Biden does over the last three and a half years.  And while we're on the subject of Joe Biden,  can\n",
      " anybody just admit that if you're going to run away from the Biden record,  you're going to run away from the Biden record?  Joe Biden is not fit to run for president.\n",
      " He ain't fit to serve as president of the United States either.\n",
      " she's not fit to serve either.  We got to get them both out of there.  We're going to get President Donald J.  Trump back in the White House.  They both have to go.  It's that simple.\n",
      " It really is.  Now, look,  the thing is,  I am a member of a community  that has been affected by all these terrible policies.\n",
      " I grew up in a working class family.  I grew up in a family where kids said other people said that kids  not going to turn out to be anything.\n",
      " I remember when I didn't have any hope for my future.  I didn't have any hope for my community.\n",
      " I thought that chaos and instability was going to be the narrative of my life,  that there was no future.  And now I'm running.  Now I'm running as Donald J.\n",
      " Trump's vice president.  It turned out pretty well for me.  Now,  here's the crazy thing,  speaking of President Trump,  and by the way,  I'll tell you a story.\n",
      " On Monday morning,  when President Trump, I guess it was Monday afternoon,  early afternoon, President Trump called to offer me the job as his vice presidential running mate,\n",
      " and I didn't answer the phone.  Now,  it went straight to voicemail or something.  I never heard it ring.  I was staring at my phone hoping that he would call me,\n",
      " but of course I called him back and we had a nice conversation.  You know,  talk a lot about this.  He put my son on the phone.  He talked to my little seven-year-old boy.  It was great.\n",
      " But the first thing he said actually when I called him back is he said,  you know, J.D., you just missed a very important phone call.  And maybe I should offer it to somebody else.  Now, he was messing with it.  He was messing with me,\n",
      " of course, because here I stand.  And I'll tell you something else about President Trump,  but I want to get to the fact that the media lies about him.\n",
      " And so many people don't realize the real President Trump.  And here's the real President Trump.  President Trump called me right before my RNC convention speech on Wednesday.\n",
      " It was a great time.  And didn't my wife do such a good job?  I was so proud of her for introducing me.  He called me and he said,  J.D., you're going to do a great job.  It was just a nice pep talk.\n",
      " He said, don't worry about anything.  You're going to do great.  And then I said,  sir, I agree with you.  I think I am going to do a good job,  but it's too late now.  No take backs.  We've already gotten here.\n",
      " And they say that he's mean spirited.  That's not the Donald Trump I know.  That's not the Donald Trump that any of us in this room know.  They also say that he's a threat to democracy.  But if I recall,\n",
      " Donald Trump  won the Republican primary in 2016,\n",
      " won the election and won another Republican primary just a few months ago.\n",
      " Democrats are the ones who want to throw out 14 million ballots and not elect Kamala Harris,  but select Kamala Harris.\n",
      " With a bunch of billionaires and Barack Obama and Nancy Pelosi making the decision instead of Democrat voters,  it's disgraceful.\n",
      " And that's the threat to American democracy,  that corruption and that broken process.\n",
      " Now, I'm obviously not a Democrat primary voter,  and I imagine none of you are either.  But if you are welcome,\n",
      " Republican Party's happy to have you.  But if you are a Democrat primary voter,\n",
      " they don't give a damn about you because they don't give a damn who you voted for.  If you are a Democrat and you look at this corrupt process,\n",
      " I invite you to the Republican Party.  We want to make America great again.  We believe in elections.  We believe in persuading voters,\n",
      " not lying to them for three and a half years and then doing a switcheroo.  It  really doesn't matter who we run against, let's be honest,\n",
      " about his mental competency,  about whether he could basically function and do the job.  Every last Democrat contender wants open borders,\n",
      " more illegal immigration.  They want more trade giveaways and they supported them from the very beginning.  They want more endless wars and more criminals on the streets.\n",
      " Ladies and gentlemen,  that is a crappy platform,  whoever they put as the figurehead of the Democratic Party.  I want to thank our likely opponent,\n",
      " Kamala Harris, because she said a couple of days ago that I showed no loyalty to the United States,  that I have no loyalty to the United States.\n",
      " Well,  you know,  I don't know Kamala.  I served in the United States Marine Corps and I built a business.\n",
      " What the hell have you done other than collect a government check for the past 20 years?  But I want to say,  my friends, whether it's Kamala Harris or anybody else,\n",
      " it's the same Democrat machine.  It's the same lies and corruption.  It is the same broken promises,  inflation crisis,  border crisis.\n",
      " We don't need any of it.  We need President Donald J.  Trump back in the White House.  Now,  before we keep going,\n",
      " I want to take a moment to thank some of the outstanding Republican leaders that we have with us today.  Republicans who I think are going to turn Virginia red in the coming decade.\n",
      " And we're so grateful to have them.  Glenn Youngkin, I understand he's working.  He's working on behalf of the state,  couldn't join us today,  but we do have Attorney General Jason Miaras.\n",
      " Thank you so much for being here,  Jason.  Thanks for your great service.  We've got Congressman Morgan Griffith.  Where's Morgan at?  There you are,  Morgan.  Thank you, man.\n",
      " Now we've got former Congressman Virgil Goode and Bob Goodlad.  Where we got,  where are they?  There they are right here.  Great.  Thank you, guys.\n",
      " A guy I've gotten to know a little bit,  an incredibly special veteran of armed forces,  a true patriot, and the next senator from the state of Virginia,  Hung Cal.  Thank you, Hung.\n",
      " Now, these are great candidates.  And of course,  we're joined by numbers of the General Assembly\n",
      " and state and local officials who are doing fantastic work on behalf of this Commonwealth.  And like I said,  they're going to help turn Virginia red.  Now,\n",
      " for those of you who don't  know me, let me just give you a little bit of background on where I come from and who  I am.  I'm a former Marine.\n",
      " Hurrah,  Semper Fi.  I graduated from the Ohio State University and Yale Law School.\n",
      " I started a business to create jobs in places like the one that I grew up in,  places that have been left behind by Washington's leadership,\n",
      " but still have a lot of grit,  a lot of determination and a lot of opportunity if we could stop screwing up in Washington, D.C.  Now,\n",
      " I was raised by my working class grandmother.  I called her Mamaw.  Do we have any other Mamaw's in the room right now?  We're in Appalachia, right?  We've got a lot of Mamaw's.\n",
      " I just want to say to all of you,  thank you for everything that you do,  especially those who are raising the Mamaw's and Papaw's, the grandparents,\n",
      " the aunts and the uncles that are raising kids they didn't expect to raise because of this terrible opioid problem that we're facing.  If you have a problem,  trust me, it's appreciated.  We love you and we're grateful to you.\n",
      " God bless you.  I'm a woman of contradiction.  She could make a sailor blush,  I'm not kidding you.  She was my guardian angel in so many ways and thanks to her,\n",
      " I had a chance to live the American dream.  And if there's anything that President Trump's leadership is about,\n",
      " it is about ensuring that your kids have access to the American dream,  that your kids have access to the incredible opportunity of this country.  Now, for years,\n",
      " Washington insiders in both parties have sold out places like Middletown,  Ohio, like Radford, Virginia.\n",
      " Both parties shipped millions of good manufacturing jobs overseas.  They decided that we didn't need to make anything in America again.\n",
      " And now we're way too dependent on the communist Chinese to make the critical decisions that they're making.  The critical things that we need from our weapons of war to the drugs that we put into the bodies of our children.\n",
      " You know 95% of the ibuprofen in this country is manufactured in China?  Guess where the majority of the antibiotics that we put into the bodies of our children are made?  In China.\n",
      " That was a decision,  ladies and gentlemen, by broken leadership that decided we didn't need to make anything in this country again.  President Trump has a different vision.\n",
      " Let's make more things in America.  Let's make our own country self-reliant.  And let's do it with American workers making good wages.  Isn't that simple?\n",
      " What's radical about thinking that we should make more of our own products in Virginia,  Ohio and Pennsylvania?  There's nothing radical about that.  It's common sense.\n",
      " And under President Trump's leadership,  my friends, we're going to change some things around and you're going to see more and more products stamped with that beautiful loco,  made in the USA.\n",
      " It's time.  Now there's nothing radical about having a national security that is strong and smart.\n",
      " Who is sick of ascending America's sons and daughters off to foreign lands they have no business in?\n",
      " We're going to focus on our own problems right here at home.  Therefore our national security depends on it.  But as President Trump showed when he took out ISIS,\n",
      " when we punch, we punch hard and we punch to win.\n",
      " There's nothing radical about telling the drug cartels and the violent gangs America is closed for business.  We don't want you in our country.  You got to go back.\n",
      " Obey the law and go back.  We're going to secure that border under President Trump's leadership.\n",
      " We're going to stop the poison fentanyl that's coming into our country and we're going to make America safe for Americans again,\n",
      " not the drug cartels and the criminals.  I just want to say,  and I don't know if you saw this at the RNC convention,  but she had a really lovely moment.\n",
      " But mom has been clean and sober for almost 10 years.  It'll be 10 years in January.  Thank you.  But I got to be honest with you.\n",
      " If the same poison that's coming across the border now was coming across the border 20 years ago,  I don't know that I would have gotten a second chance with my mother.\n",
      " And there are a lot of families all across this country  who not getting second chances\n",
      " with their loved ones because the cartels are bringing poison across this country at  a level we have never seen.  We have got to shut that border down,\n",
      " make America safe again.  It's common sense.  It's not radical.  And we're going to do it under President Donald Trump's leadership.\n",
      " Now, I don't know if any of you watched the RNC convention,  did you?  It went pretty well, right?  But you know, something happens.\n",
      " There was a speaker at the RNC convention.  She spoke  about her 15 year old son  who had taken one pill under peer pressure and it happened to\n",
      " be laced with fentanyl and it took its life.  Isn't that so sad?  A handsome,  gorgeous little boy,\n",
      " one mistake and now his mother will mourn him for the rest of her life.  That is the fruit  of Joe Biden's open border and I'm sick of it.\n",
      " I'm sick of allowing this stuff into our country.  I heard people say after this woman gave her speech,  really disgraceful, disgusting people say, well,\n",
      " maybe he shouldn't have taken that pill to begin with.  And I've got three little kids myself.  I've got a seven year old,  a four year old and two year old.  And we all know kids make mistakes.\n",
      " I want to grow up in a country,\n",
      " I want them to grow up in a country where a simple,  you can work in a manufacturing economy where we make things with our own hands and we do it with American workers.\n",
      " I want my children to grow up in a world where they go to school and they learn reading,\n",
      " writing and arithmetic,  not indoctrination from crazy progressives who want to talk about sex in the classroom instead of education.\n",
      " I want my kids to grow up in a country where the police are respected and they're empowered\n",
      " to keep our children safe and secure in their own neighborhoods.\n",
      " I want my children to grow up in that country and the only way it's going to happen if we make better decisions in Washington,\n",
      " D.C., we have got to send Donald J.  Trump back to the White House to do all these things and so much more.\n",
      " My friends, I'm so grateful to be here with you today.  I'm grateful to stand on this stage.\n",
      " I'm grateful for the incredible opportunities that this country has afforded me and I'm grateful to be President Donald J.  Trump's running mate.\n",
      " We've got an incredible opportunity here.  We've got an opportunity to win races up and down the ballot.\n",
      " We have the opportunity to reestablish American energy dominance,  restore American manufacturing,\n",
      " defeat this crazy inflation and kick the drug cartels the hell out of our country.  So  to everybody listening,\n",
      " certainly to Radford, Virginia, but all across this Commonwealth and forgotten communities in Virginia,  Michigan,  Wisconsin, Pennsylvania and Ohio,\n",
      " I make this very simple promise to you.  I will fight.  President Trump will fight.  We will fight every single day.\n",
      " Every single day to restore an America that works for you,  for your children and for your grandchildren.\n",
      " We'll fight to bring down the cost of groceries and housing.\n",
      " Isn't it a shame that our young people can't afford to buy a home in Joe Biden and Kamala Harris's economy?  We'll fight to bring down the cost of energy and  energy.  We'll fight to close the border.\n",
      " We'll fight to get this fentanyl out of our communities.  We will do all of these things.  But the only way to do it is to reelect President Donald J.  Trump,\n",
      "(130, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1164916/52643411.py:252: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  fil_df = adf[adf.total > (threshold/1.75)][adf.word_count >= 6].reset_index(drop = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping duplicates (129, 10)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a,b = sentence_splitter(\"/home/suryasss/Transcription/SSA_2/target_speaker.wav\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_no</th>\n",
       "      <th>new_start_time</th>\n",
       "      <th>new_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.53</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.10</td>\n",
       "      <td>10.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>429</td>\n",
       "      <td>1267.78</td>\n",
       "      <td>1268.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>1268.92</td>\n",
       "      <td>1270.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>431</td>\n",
       "      <td>1270.52</td>\n",
       "      <td>1271.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>432</td>\n",
       "      <td>1271.64</td>\n",
       "      <td>1273.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>1273.30</td>\n",
       "      <td>1276.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     segment_no  new_start_time  new_end_time\n",
       "0             0            0.00          1.73\n",
       "1             1            1.93          3.53\n",
       "2             2            3.53          5.95\n",
       "3             3            5.95          6.90\n",
       "4             4            7.10         10.44\n",
       "..          ...             ...           ...\n",
       "429         429         1267.78       1268.92\n",
       "430         430         1268.92       1270.52\n",
       "431         431         1270.52       1271.64\n",
       "432         432         1271.64       1273.30\n",
       "433         433         1273.30       1276.77\n",
       "\n",
       "[434 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated segments saved to updated_segments.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = a\n",
    "\n",
    "# Load the original audio file\n",
    "original_audio = AudioSegment.from_file(\"/home/suryasss/Transcription/SSA_2/target_speaker.wav\")\n",
    "\n",
    "# Initialize the final audio segment\n",
    "final_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "# Define the duration for non-segment to be added (1 second)\n",
    "non_segment_duration = 0.2 * 1000  # pydub works with milliseconds\n",
    "\n",
    "# Initialize a list to store updated segment times\n",
    "updated_times = []\n",
    "\n",
    "# Track the current position in the final_audio\n",
    "current_position = 0\n",
    "df[\"shifted_start\"] = df[\"start\"].shift(-1).fillna(df[\"end\"])\n",
    "df[\"end\"] = np.where((df[\"end\"] + 0.2) >= df[\"shifted_start\"],df[\"shifted_start\"],df[\"end\"] + 0.2)\n",
    "# Append the first segment\n",
    "first_segment_start_time = df.iloc[0]['start'] * 1000  # Convert to milliseconds\n",
    "first_segment_end_time = df.iloc[0]['end'] * 1000  # Convert to milliseconds\n",
    "first_segment = original_audio[first_segment_start_time:first_segment_end_time]\n",
    "final_audio += first_segment\n",
    "\n",
    "updated_times.append({\n",
    "    'segment_no': df.iloc[0]['segment_no'],\n",
    "    'new_start_time': current_position / 1000,  # Convert back to seconds\n",
    "    'new_end_time': (current_position + len(first_segment)) / 1000  # Convert back to seconds\n",
    "})\n",
    "\n",
    "# Update current position\n",
    "current_position += len(first_segment)\n",
    "\n",
    "# Loop through each pair of segments\n",
    "for i in range(1, len(df)):\n",
    "    prev_segment_end_time = df.iloc[i-1]['end'] * 1000  # End of previous segment\n",
    "    current_segment_start_time = df.iloc[i]['start'] * 1000  # Start of current segment\n",
    "    current_segment_end_time = df.iloc[i]['end'] * 1000  # End of current segment\n",
    "    \n",
    "    # Calculate the duration of gap to use\n",
    "    gap_duration = min(non_segment_duration, current_segment_start_time - prev_segment_end_time)\n",
    "    \n",
    "    # Add the non-segment part\n",
    "    if gap_duration > 0.5:\n",
    "        non_segment = original_audio[prev_segment_end_time:prev_segment_end_time + gap_duration]\n",
    "    else:\n",
    "        non_segment = AudioSegment.silent(duration=0.5)\n",
    "    final_audio += non_segment\n",
    "    current_position += len(non_segment)\n",
    "    \n",
    "    # Add the current segment\n",
    "    current_segment = original_audio[current_segment_start_time:current_segment_end_time]\n",
    "    final_audio += current_segment\n",
    "    \n",
    "    # Store the updated times\n",
    "    updated_times.append({\n",
    "        'segment_no': df.iloc[i]['segment_no'],\n",
    "        'new_start_time': current_position / 1000,  # Convert back to seconds\n",
    "        'new_end_time': (current_position + len(current_segment)) / 1000  # Convert back to seconds\n",
    "    })\n",
    "    \n",
    "    # Update current position\n",
    "    current_position += len(current_segment)\n",
    "\n",
    "# Create a new DataFrame with updated times\n",
    "updated_df = pd.DataFrame(updated_times)\n",
    "\n",
    "# Export the final audio\n",
    "final_audio.export(\"check.wav\", format=\"wav\")\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_df.to_csv('updated_segments.csv', index=False)\n",
    "\n",
    "print(f\"Updated segments saved to updated_segments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2.20\n",
       "1         3.80\n",
       "2         6.22\n",
       "3        10.22\n",
       "4        13.56\n",
       "        ...   \n",
       "429    1725.40\n",
       "430    1727.00\n",
       "431    1728.12\n",
       "432    1729.78\n",
       "433        NaN\n",
       "Name: start, Length: 434, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"start\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_no</th>\n",
       "      <th>new_start_time</th>\n",
       "      <th>new_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.75</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6.70</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>429</td>\n",
       "      <td>1297.87</td>\n",
       "      <td>1299.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>1299.18</td>\n",
       "      <td>1300.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>431</td>\n",
       "      <td>1300.93</td>\n",
       "      <td>1302.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>432</td>\n",
       "      <td>1302.36</td>\n",
       "      <td>1303.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>1304.02</td>\n",
       "      <td>1307.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     segment_no  new_start_time  new_end_time\n",
       "0             0            0.00          1.23\n",
       "1             1            1.73          3.16\n",
       "2             2            3.33          5.28\n",
       "3             3            5.75          6.20\n",
       "4             4            6.70          9.71\n",
       "..          ...             ...           ...\n",
       "429         429         1297.87       1299.18\n",
       "430         430         1299.18       1300.93\n",
       "431         431         1300.93       1302.36\n",
       "432         432         1302.36       1303.95\n",
       "433         433         1304.02       1307.39\n",
       "\n",
       "[434 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='check.wav'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = a\n",
    "\n",
    "# Load the original audio file\n",
    "original_audio = AudioSegment.from_file(\"/home/suryasss/Transcription/SSA/target_speaker.wav\")\n",
    "\n",
    "# Initialize the final audio segment\n",
    "final_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "# Define the duration for non-segment to be added (1 second)\n",
    "non_segment_duration = 0.3 * 1000  # pydub works with milliseconds\n",
    "\n",
    "# Append the first segment\n",
    "first_segment_start_time = df.iloc[0]['start'] * 1000  # Convert to milliseconds\n",
    "first_segment_end_time = df.iloc[0]['end'] * 1000  # Convert to milliseconds\n",
    "final_audio += original_audio[first_segment_start_time:first_segment_end_time]\n",
    "\n",
    "# Loop through each pair of segments\n",
    "for i in range(1, len(df)):\n",
    "    prev_segment_end_time = df.iloc[i-1]['end'] * 1000  # End of previous segment\n",
    "    current_segment_start_time = df.iloc[i]['start'] * 1000  # Start of current segment\n",
    "    current_segment_end_time = df.iloc[i]['end'] * 1000  # End of current segment\n",
    "    \n",
    "    # Calculate the duration of gap to use\n",
    "    gap_duration = min(non_segment_duration, current_segment_start_time - prev_segment_end_time)\n",
    "    \n",
    "    # Add the non-segment part\n",
    "    if gap_duration > 0:\n",
    "        non_segment = original_audio[prev_segment_end_time:prev_segment_end_time + gap_duration]\n",
    "    else:\n",
    "        non_segment = AudioSegment.silent(duration=0)\n",
    "    final_audio += non_segment\n",
    "    \n",
    "    # Add the current segment\n",
    "    current_segment = original_audio[current_segment_start_time:current_segment_end_time]\n",
    "    final_audio += current_segment\n",
    "\n",
    "# Export the final audio\n",
    "final_audio.export(\"check.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryasss/.conda/envs/ssconda/lib/python3.12/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "Transcribe: 100%|██████████| 2515.91/2515.91 [02:34<00:00, 16.32sec/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment no</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>total</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>Yeah,</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.35</td>\n",
       "      <td>that's right.</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.63</td>\n",
       "      <td>So she,</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.25</td>\n",
       "      <td>when he came home drunk,</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.12</td>\n",
       "      <td>5.29</td>\n",
       "      <td>he passed out on the couch.</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1164</td>\n",
       "      <td>2491.48</td>\n",
       "      <td>2493.53</td>\n",
       "      <td>A Memoir of Family and Culture and Crisis.</td>\n",
       "      <td>2.05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>1165</td>\n",
       "      <td>2493.84</td>\n",
       "      <td>2494.35</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>1166</td>\n",
       "      <td>2494.56</td>\n",
       "      <td>2495.07</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>1167</td>\n",
       "      <td>2495.74</td>\n",
       "      <td>2497.69</td>\n",
       "      <td>For Uncommon Knowledge and the Hoover Institu...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>1168</td>\n",
       "      <td>2498.10</td>\n",
       "      <td>2498.89</td>\n",
       "      <td>I'm Peter Robinson.</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1169 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Segment no    start      end  \\\n",
       "0              0     0.00     0.35   \n",
       "1              1     0.52     1.35   \n",
       "2              2     1.70     2.63   \n",
       "3              3     3.30     4.25   \n",
       "4              4     4.12     5.29   \n",
       "...          ...      ...      ...   \n",
       "1164        1164  2491.48  2493.53   \n",
       "1165        1165  2493.84  2494.35   \n",
       "1166        1166  2494.56  2495.07   \n",
       "1167        1167  2495.74  2497.69   \n",
       "1168        1168  2498.10  2498.89   \n",
       "\n",
       "                                                   text  total  word_count  \n",
       "0                                                 Yeah,   0.35           1  \n",
       "1                                         that's right.   0.83           2  \n",
       "2                                               So she,   0.93           2  \n",
       "3                              when he came home drunk,   0.95           5  \n",
       "4                           he passed out on the couch.   1.17           6  \n",
       "...                                                 ...    ...         ...  \n",
       "1164         A Memoir of Family and Culture and Crisis.   2.05           8  \n",
       "1165                                         Thank you.   0.51           2  \n",
       "1166                                         Thank you.   0.51           2  \n",
       "1167   For Uncommon Knowledge and the Hoover Institu...   1.95           7  \n",
       "1168                                I'm Peter Robinson.   0.79           3  \n",
       "\n",
       "[1169 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_splitter(\"/home/suryasss/Transcription/SSA/target_speaker.wav\",1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
